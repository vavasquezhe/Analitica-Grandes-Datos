{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedc811d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Repaso Pig\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba9f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analítica de Grandes Datos\n",
    "* ##### Facultad de Minas\n",
    "* ##### Universidad Nacional de Colombia\n",
    "* ##### Autor: Valentina Vásquez Hernandez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a667adc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 0. ¿Cómo ejecuto el código de este taller?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ba33a",
   "metadata": {},
   "source": [
    "* **Paso 1.** Ejecutar la imagen de docker `jdvelasq/pig:0.17.0` [click aquí para ver el comando](https://jdvelasq.github.io/courses/analitica_de_grandes_datos/index.html)\n",
    "* **Paso 2.** Una vez se encuentren dentro de la imágen, pueden seguir cualquiera de las siguientes opciones: \n",
    "    > **Paso 2.1.** Clonar el repositorio de los talleres dentro de su máquina e inicializar jupyter [lab o notebook] en el directorio donde se encuentre este libro .ipynb\n",
    "    \n",
    "    > **Paso 2.2.** Guardar comandos en un archivo `.pig` y luego ejecutarlo con el comando `pig -execute`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b7730",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470876c2",
   "metadata": {},
   "source": [
    "### 1. ¿Qué es Apache Pig?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efa1ad",
   "metadata": {},
   "source": [
    "Apache Pig es una plataforma flujo de trabajo *OpenSource* para grandes datos que permite el analisis de la información a través de la ejecución de programas de MapReduce en Hadoop. El lenguaje mediante el que se puede interactuar con el sistema se llama `Pig Latin` [1](https://pig.apache.org/about.html) \n",
    "\n",
    "Con respecto a lo que se ha explorado dentro de las funciones MapReduce y otras implementaciones, `Pig` presenta las siguientes ventajas: \n",
    "\n",
    "* Tiene implementados comandos especificos para el conteo (reduce).\n",
    "* No es necesario escribir explicitamente el mapper y el reducer en Java o Python.\n",
    "* Convierte queries, que es un lenguaje fácil de aprender e impleemntar, en funciones de MapReduce.\n",
    "* Acepta todo tipo de dato, incluso los anidados. Entre estos se encuentran int, float, datetime, chararray, entre otros.\n",
    "\n",
    "\n",
    "\n",
    "> **Arquitectura Pig** [2](https://forum.huawei.com/enterprise/es/apache-pig/thread/861847-100759)\n",
    "\n",
    "\n",
    "<img src=\"pigarq.jpg\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa35fb9",
   "metadata": {},
   "source": [
    "**Jerarquía**\n",
    "> Map []\n",
    ">> Bag {(a,b),(c,d)}\n",
    ">>> Tuple (a,b)\n",
    "\n",
    "\n",
    "**Principales comandos:**\n",
    "\n",
    "* `LOAD`, `CROSS`, `DISTINCT`, `FILTER`, `FOREACH`, `GROUP`, `LIMIT`, `ORDER BY`, `SPLIT`, `UNION`\n",
    "* `AVG`, `CONCAT`, `COUNT`, `IN`, `MAX`, `MIN`, `SIZE`, `SUM`, `TOKENIZE`\n",
    "* `ABS`, `CBRT`, `CEIL`, `FLOOR`, `LOG`, `LOG10`, `ROUND`, `SQRT`\n",
    "\n",
    "\n",
    "*Documentación*: https://pig.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74bdae",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo uso Pig?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadadc1",
   "metadata": {},
   "source": [
    "Es posible ejecutar Pig de manera local, pseudodistribuido o usando directamente HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4827c73d-f519-478c-8fdd-246cd6577c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Desktop/Maestría Ingeniería - Analítica/2022-01_Monitoria_AnaliticaGrandesDatos/Analitica-Grandes-Datos\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7579b6-0ff6-414b-9d73-5f823d214187",
   "metadata": {},
   "source": [
    "A continuación se crea la base de datos a usar y se establece el esquema de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a303da-6a59-4314-af99-efe7fd152fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_fueltype_price.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_fueltype_price.pig\n",
    "\n",
    "-- carga de datos desde la carpeta local\n",
    "cars_table = LOAD 'data/cars_subset.csv' USING PigStorage(',')\n",
    "    AS (\n",
    "            car_id:int,\n",
    "            make:chararray,\n",
    "            fuel_type:chararray,\n",
    "            length:float,\n",
    "            width:float,\n",
    "            height:float,\n",
    "            price:int\n",
    "\n",
    "    );\n",
    "\n",
    "specific_columns = FOREACH cars_table GENERATE make, fuel_type, price;\n",
    "STORE specific_columns INTO 'output';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd6bbdd-5573-4c21-99c3-819292c35cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 21:44:21,297 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2022-06-13 21:44:21,441 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:21,578 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2022-06-13 21:44:21,599 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2022-06-13 21:44:21,652 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2022-06-13 21:44:21,900 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1976651350_0001\n",
      "2022-06-13 21:44:22,002 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2022-06-13 21:44:22,006 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2022-06-13 21:44:22,035 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:22,035 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:22,036 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2022-06-13 21:44:22,093 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2022-06-13 21:44:22,095 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1976651350_0001_m_000000_0\n",
      "2022-06-13 21:44:22,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:22,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:22,186 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2022-06-13 21:44:22,200 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 5505\n",
      "Input split[0]:\n",
      "   Length = 5505\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2022-06-13 21:44:22,222 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:22,222 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:22,330 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:44:22,332 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1976651350_0001_m_000000_0 is done. And is in the process of committing\n",
      "2022-06-13 21:44:22,360 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:44:22,360 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1976651350_0001_m_000000_0 is allowed to commit now\n",
      "2022-06-13 21:44:22,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1976651350_0001_m_000000_0' to file:/workspace/Desktop/Maestría Ingeniería - Analítica/2022-01_Monitoria_AnaliticaGrandesDatos/Analitica-Grandes-Datos/output/_temporary/0/task_local1976651350_0001_m_000000\n",
      "2022-06-13 21:44:22,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2022-06-13 21:44:22,380 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1976651350_0001_m_000000_0' done.\n",
      "2022-06-13 21:44:22,394 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1976651350_0001_m_000000_0: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6035\n",
      "\t\tFILE: Number of bytes written=484166\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=159\n",
      "\t\tMap output records=159\n",
      "\t\tInput split bytes=474\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=129499136\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\torg.apache.pig.PigWarning\n",
      "\t\tACCESSING_NON_EXISTENT_FIELD=159\n",
      "2022-06-13 21:44:22,394 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1976651350_0001_m_000000_0\n",
      "2022-06-13 21:44:22,396 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2022-06-13 21:44:22,519 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:22,537 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:22,539 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:22,581 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:22,599 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:22,600 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!pig -x local -execute 'run make_fueltype_price.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912e2283-56cd-43f7-b4fc-5f462edb2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas\tfour\t\n",
      "gas\tfour\t\n",
      "gas\tfour\t\n",
      "gas\tfour\t\n",
      "gas\ttwo\t\n",
      "gas\tfour\t\n",
      "gas\ttwo\t\n",
      "gas\tfour\t\n",
      "gas\ttwo\t\n",
      "gas\ttwo\t\n"
     ]
    }
   ],
   "source": [
    "!head output/part-m-*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6c359",
   "metadata": {},
   "source": [
    "A continuación se genera el conteo de frecuencia para una de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b4154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fueltype_count.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile fueltype_count.pig\n",
    "-- carga de datos desde la carpeta local\n",
    "cars_table = LOAD 'data/cars_subset.csv' USING PigStorage(',')\n",
    "    AS (\n",
    "            car_id:int,\n",
    "            make:chararray,\n",
    "            fuel_type:chararray,\n",
    "            length:float,\n",
    "            width:float,\n",
    "            height:float,\n",
    "            price:int\n",
    "\n",
    "    );\n",
    "words = FOREACH cars_table GENERATE FLATTEN(TOKENIZE(fuel_type)) AS word;\n",
    "grouped = GROUP words BY word;\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "STORE wordcount INTO 'output_wordcount';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a20cb87-b68b-4126-81f3-6cbf0bc9d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 21:44:34,079 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2022-06-13 21:44:34,273 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:34,371 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2022-06-13 21:44:34,403 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2022-06-13 21:44:34,461 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2022-06-13 21:44:34,697 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1422260926_0001\n",
      "2022-06-13 21:44:34,801 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2022-06-13 21:44:34,807 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2022-06-13 21:44:34,850 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:34,850 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:34,855 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2022-06-13 21:44:34,919 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2022-06-13 21:44:34,919 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1422260926_0001_m_000000_0\n",
      "2022-06-13 21:44:34,977 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:34,977 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:35,011 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2022-06-13 21:44:35,021 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 5505\n",
      "Input split[0]:\n",
      "   Length = 5505\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2022-06-13 21:44:35,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2022-06-13 21:44:35,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2022-06-13 21:44:35,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2022-06-13 21:44:35,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2022-06-13 21:44:35,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2022-06-13 21:44:35,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2022-06-13 21:44:35,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:44:35,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2022-06-13 21:44:35,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2022-06-13 21:44:35,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1844; bufvoid = 104857600\n",
      "2022-06-13 21:44:35,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213764(104855056); length = 633/6553600\n",
      "2022-06-13 21:44:35,479 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2022-06-13 21:44:35,558 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1422260926_0001_m_000000_0 is done. And is in the process of committing\n",
      "2022-06-13 21:44:35,594 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2022-06-13 21:44:35,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1422260926_0001_m_000000_0' done.\n",
      "2022-06-13 21:44:35,614 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1422260926_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6035\n",
      "\t\tFILE: Number of bytes written=514930\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=159\n",
      "\t\tMap output records=159\n",
      "\t\tMap output bytes=1844\n",
      "\t\tMap output materialized bytes=35\n",
      "\t\tInput split bytes=474\n",
      "\t\tCombine input records=159\n",
      "\t\tCombine output records=2\n",
      "\t\tSpilled Records=2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=231211008\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2022-06-13 21:44:35,614 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1422260926_0001_m_000000_0\n",
      "2022-06-13 21:44:35,619 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2022-06-13 21:44:35,623 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2022-06-13 21:44:35,624 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1422260926_0001_r_000000_0\n",
      "2022-06-13 21:44:35,646 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:35,646 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:35,650 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2022-06-13 21:44:35,656 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e8bde21\n",
      "2022-06-13 21:44:35,682 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2022-06-13 21:44:35,686 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1422260926_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2022-06-13 21:44:35,709 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1422260926_0001_m_000000_0 decomp: 31 len: 35 to MEMORY\n",
      "2022-06-13 21:44:35,728 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 31 bytes from map-output for attempt_local1422260926_0001_m_000000_0\n",
      "2022-06-13 21:44:35,730 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31\n",
      "2022-06-13 21:44:35,733 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2022-06-13 21:44:35,742 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2022-06-13 21:44:35,742 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2022-06-13 21:44:35,749 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2022-06-13 21:44:35,749 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 23 bytes\n",
      "2022-06-13 21:44:35,750 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 31 bytes to disk to satisfy reduce memory limit\n",
      "2022-06-13 21:44:35,751 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 35 bytes from disk\n",
      "2022-06-13 21:44:35,752 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2022-06-13 21:44:35,753 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2022-06-13 21:44:35,755 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 23 bytes\n",
      "2022-06-13 21:44:35,756 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2022-06-13 21:44:35,778 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:44:35,778 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:44:35,818 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1422260926_0001_r_000000_0 is done. And is in the process of committing\n",
      "2022-06-13 21:44:35,834 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2022-06-13 21:44:35,835 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1422260926_0001_r_000000_0 is allowed to commit now\n",
      "2022-06-13 21:44:35,849 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1422260926_0001_r_000000_0' to file:/workspace/Desktop/Maestría Ingeniería - Analítica/2022-01_Monitoria_AnaliticaGrandesDatos/Analitica-Grandes-Datos/output_wordcount/_temporary/0/task_local1422260926_0001_r_000000\n",
      "2022-06-13 21:44:35,850 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2022-06-13 21:44:35,850 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1422260926_0001_r_000000_0' done.\n",
      "2022-06-13 21:44:35,851 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1422260926_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6137\n",
      "\t\tFILE: Number of bytes written=514992\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=35\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=231211008\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2022-06-13 21:44:35,851 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1422260926_0001_r_000000_0\n",
      "2022-06-13 21:44:35,852 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2022-06-13 21:44:36,123 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:36,149 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:36,150 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:36,209 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:36,209 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:44:36,210 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!pig -x local -execute 'run fueltype_count.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64cc2f93-a86b-44cf-a663-27501fe3f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two\t64\n",
      "four\t95\n"
     ]
    }
   ],
   "source": [
    "!head output_wordcount/part-r-* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18571abc-9db8-41fc-b310-6e646e10838c",
   "metadata": {},
   "source": [
    "A continuación se general metricas por cada una de las marcas y se almacenan en salidas diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf9b021-6082-4c4a-9dc1-654d2bc6eed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_report_template.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_report_template.pig\n",
    "-- carga de datos desde la carpeta local\n",
    "cars_table = LOAD 'data/cars_subset.csv' USING PigStorage(',')\n",
    "    AS (\n",
    "            car_id:int,\n",
    "            make:chararray,\n",
    "            fuel_type:chararray,\n",
    "            length:float,\n",
    "            width:float,\n",
    "            height:float,\n",
    "            price:int\n",
    "\n",
    "    );\n",
    "    \n",
    "filtered = FILTER cars_table BY (make MATCHES {}{}{});\n",
    "STORE filtered INTO {}{}{};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010e4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pig_file(make):\n",
    "    file = open(\"make_report_template.pig\", 'r').read()\n",
    "    pig_query = file.format(\"'\",str(make),\"'\",\"'\",'output_'+str(make),\"'\")\n",
    "    pig_file_path = \"make_report_{}.pig\".format(make)\n",
    "    with open(pig_file_path, 'w') as f:\n",
    "        f.write(pig_query)\n",
    "    f.close()\n",
    "    return pig_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8018690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make_report_mazda.pig'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pig_file(\"mazda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c204cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'make_report_toyota.pig'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pig_file(\"toyota\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43bccf05-5172-4984-91d4-eb696a5dcda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 21:45:17,752 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2022-06-13 21:45:17,877 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:18,033 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2022-06-13 21:45:18,056 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2022-06-13 21:45:18,103 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2022-06-13 21:45:18,347 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1636098767_0001\n",
      "2022-06-13 21:45:18,463 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2022-06-13 21:45:18,466 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2022-06-13 21:45:18,494 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:18,494 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:18,495 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2022-06-13 21:45:18,546 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2022-06-13 21:45:18,547 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1636098767_0001_m_000000_0\n",
      "2022-06-13 21:45:18,602 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:18,602 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:18,637 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2022-06-13 21:45:18,648 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 5505\n",
      "Input split[0]:\n",
      "   Length = 5505\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2022-06-13 21:45:18,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:18,671 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:18,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:45:18,798 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1636098767_0001_m_000000_0 is done. And is in the process of committing\n",
      "2022-06-13 21:45:18,816 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:45:18,816 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1636098767_0001_m_000000_0 is allowed to commit now\n",
      "2022-06-13 21:45:18,827 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1636098767_0001_m_000000_0' to file:/workspace/Desktop/Maestría Ingeniería - Analítica/2022-01_Monitoria_AnaliticaGrandesDatos/Analitica-Grandes-Datos/output_toyota/_temporary/0/task_local1636098767_0001_m_000000\n",
      "2022-06-13 21:45:18,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2022-06-13 21:45:18,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1636098767_0001_m_000000_0' done.\n",
      "2022-06-13 21:45:18,843 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1636098767_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6035\n",
      "\t\tFILE: Number of bytes written=489978\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=159\n",
      "\t\tMap output records=159\n",
      "\t\tInput split bytes=474\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=153616384\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\torg.apache.pig.PigWarning\n",
      "\t\tACCESSING_NON_EXISTENT_FIELD=159\n",
      "\t\tFIELD_DISCARDED_TYPE_CONVERSION_FAILED=159\n",
      "2022-06-13 21:45:18,844 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1636098767_0001_m_000000_0\n",
      "2022-06-13 21:45:18,845 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2022-06-13 21:45:18,982 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:18,999 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:19,000 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:19,030 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:19,031 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:19,032 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!pig -x local -execute 'run make_report_toyota.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27b71d65-22f2-4894-8358-11147b6443be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-13 21:45:25,286 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2022-06-13 21:45:25,419 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:25,560 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2022-06-13 21:45:25,580 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2022-06-13 21:45:25,724 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2022-06-13 21:45:26,029 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1717844432_0001\n",
      "2022-06-13 21:45:26,138 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2022-06-13 21:45:26,141 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2022-06-13 21:45:26,183 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:26,183 [Thread-5] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:26,184 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2022-06-13 21:45:26,233 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2022-06-13 21:45:26,233 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1717844432_0001_m_000000_0\n",
      "2022-06-13 21:45:26,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:26,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:26,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2022-06-13 21:45:26,337 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 5505\n",
      "Input split[0]:\n",
      "   Length = 5505\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2022-06-13 21:45:26,357 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2022-06-13 21:45:26,357 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2022-06-13 21:45:26,483 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:45:26,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1717844432_0001_m_000000_0 is done. And is in the process of committing\n",
      "2022-06-13 21:45:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2022-06-13 21:45:26,510 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1717844432_0001_m_000000_0 is allowed to commit now\n",
      "2022-06-13 21:45:26,517 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1717844432_0001_m_000000_0' to file:/workspace/Desktop/Maestría Ingeniería - Analítica/2022-01_Monitoria_AnaliticaGrandesDatos/Analitica-Grandes-Datos/output_mazda/_temporary/0/task_local1717844432_0001_m_000000\n",
      "2022-06-13 21:45:26,518 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2022-06-13 21:45:26,518 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1717844432_0001_m_000000_0' done.\n",
      "2022-06-13 21:45:26,531 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1717844432_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6035\n",
      "\t\tFILE: Number of bytes written=489960\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=159\n",
      "\t\tMap output records=159\n",
      "\t\tInput split bytes=474\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=142082048\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "\torg.apache.pig.PigWarning\n",
      "\t\tACCESSING_NON_EXISTENT_FIELD=159\n",
      "\t\tFIELD_DISCARDED_TYPE_CONVERSION_FAILED=159\n",
      "2022-06-13 21:45:26,531 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1717844432_0001_m_000000_0\n",
      "2022-06-13 21:45:26,533 [Thread-5] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2022-06-13 21:45:26,757 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:26,775 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:26,777 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:26,811 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:26,812 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2022-06-13 21:45:26,813 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!pig -x local -execute 'run make_report_mazda.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d91b66-4e8b-4498-b516-d53587994df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgas\tfour\t176.6\t66.2\t13950.0\t\n",
      "\tgas\tfour\t176.6\t66.4\t17450.0\t\n",
      "\tgas\tfour\t192.7\t71.4\t17710.0\t\n",
      "\tgas\tfour\t192.7\t71.4\t23875.0\t\n",
      "\tgas\ttwo\t176.8\t64.8\t16430.0\t\n",
      "\tgas\tfour\t176.8\t64.8\t16925.0\t\n",
      "\tgas\ttwo\t176.8\t64.8\t20970.0\t\n",
      "\tgas\tfour\t176.8\t64.8\t21105.0\t\n",
      "\tgas\ttwo\t141.1\t60.3\t5151.0\t\n",
      "\tgas\ttwo\t155.9\t63.6\t6295.0\t\n",
      "\tgas\tfour\t158.8\t63.6\t6575.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t5572.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t6377.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t7957.0\t\n",
      "\tgas\tfour\t157.3\t63.8\t6229.0\t\n",
      "\tgas\tfour\t157.3\t63.8\t6692.0\t\n",
      "\tgas\tfour\t157.3\t63.8\t7609.0\t\n",
      "\tgas\tfour\t174.6\t64.6\t8921.0\t\n",
      "\tgas\ttwo\t173.2\t66.3\t12964.0\t\n",
      "\tgas\ttwo\t144.6\t63.9\t6479.0\t\n",
      "\tgas\ttwo\t144.6\t63.9\t6855.0\t\n",
      "\tgas\ttwo\t150.0\t64.0\t5399.0\t\n",
      "\tgas\ttwo\t150.0\t64.0\t6529.0\t\n",
      "\tgas\ttwo\t150.0\t64.0\t7129.0\t\n",
      "\tgas\tfour\t163.4\t64.0\t7295.0\t\n",
      "\tgas\tfour\t157.1\t63.9\t7295.0\t\n",
      "\tgas\ttwo\t167.5\t65.2\t7895.0\t\n",
      "\tgas\ttwo\t167.5\t65.2\t9095.0\t\n",
      "\tgas\tfour\t175.4\t65.2\t8845.0\t\n",
      "\tgas\tfour\t175.4\t62.5\t10295.0\t\n",
      "\tgas\tfour\t175.4\t65.2\t12945.0\t\n",
      "\tgas\ttwo\t169.1\t66.0\t10345.0\t\n",
      "\tgas\tfour\t199.6\t69.6\t32250.0\t\n",
      "\tgas\ttwo\t159.1\t64.2\t5195.0\t\n",
      "\tgas\ttwo\t159.1\t64.2\t6095.0\t\n",
      "\tgas\ttwo\t159.1\t64.2\t6795.0\t\n",
      "\tgas\tfour\t166.8\t64.2\t6695.0\t\n",
      "\tgas\tfour\t166.8\t64.2\t7395.0\t\n",
      "\tgas\ttwo\t177.8\t66.5\t8845.0\t\n",
      "\tgas\tfour\t177.8\t66.5\t8495.0\t\n",
      "\tgas\ttwo\t177.8\t66.5\t10595.0\t\n",
      "\tgas\tfour\t177.8\t66.5\t10245.0\t\n",
      "\tgas\tfour\t177.8\t66.5\t11245.0\t\n",
      "\tgas\tfour\t175.0\t66.1\t18280.0\t\n",
      "\tdiesel\tfour\t190.9\t70.3\t25552.0\t\n",
      "\tdiesel\tfour\t190.9\t70.3\t28248.0\t\n",
      "\tdiesel\ttwo\t187.5\t70.3\t28176.0\t\n",
      "\tdiesel\tfour\t202.6\t71.7\t31600.0\t\n",
      "\tgas\ttwo\t180.3\t70.5\t35056.0\t\n",
      "\tgas\ttwo\t157.3\t64.4\t5389.0\t\n",
      "\tgas\ttwo\t157.3\t64.4\t6189.0\t\n",
      "\tgas\ttwo\t157.3\t64.4\t6669.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t7689.0\t\n",
      "\tgas\ttwo\t173.0\t65.4\t9959.0\t\n",
      "\tgas\ttwo\t173.0\t65.4\t8499.0\t\n",
      "\tgas\tfour\t172.4\t65.4\t6989.0\t\n",
      "\tgas\tfour\t172.4\t65.4\t8189.0\t\n",
      "\tgas\tfour\t172.4\t65.4\t9279.0\t\n",
      "\tgas\tfour\t172.4\t65.4\t9279.0\t\n",
      "\tgas\ttwo\t165.3\t63.8\t5499.0\t\n",
      "\tdiesel\ttwo\t165.3\t63.8\t7099.0\t\n",
      "\tgas\ttwo\t165.3\t63.8\t6649.0\t\n",
      "\tgas\tfour\t165.3\t63.8\t6849.0\t\n",
      "\tgas\tfour\t170.2\t63.8\t7349.0\t\n",
      "\tgas\ttwo\t165.3\t63.8\t7299.0\t\n",
      "\tgas\ttwo\t165.6\t63.8\t7799.0\t\n",
      "\tgas\tfour\t165.3\t63.8\t7499.0\t\n",
      "\tgas\tfour\t170.2\t63.8\t7999.0\t\n",
      "\tgas\ttwo\t162.4\t63.8\t8249.0\t\n",
      "\tgas\tfour\t173.4\t65.2\t8949.0\t\n",
      "\tgas\tfour\t173.4\t65.2\t9549.0\t\n",
      "\tgas\tfour\t181.7\t66.5\t13499.0\t\n",
      "\tgas\tfour\t184.6\t66.5\t14399.0\t\n",
      "\tgas\tfour\t184.6\t66.5\t13499.0\t\n",
      "\tgas\ttwo\t170.7\t67.9\t17199.0\t\n",
      "\tgas\ttwo\t170.7\t67.9\t19699.0\t\n",
      "\tgas\ttwo\t178.5\t67.9\t18399.0\t\n",
      "\tgas\tfour\t186.7\t68.4\t11900.0\t\n",
      "\tdiesel\tfour\t186.7\t68.4\t13200.0\t\n",
      "\tgas\tfour\t186.7\t68.4\t15580.0\t\n",
      "\tdiesel\tfour\t186.7\t68.4\t16900.0\t\n",
      "\tgas\tfour\t186.7\t68.4\t16630.0\t\n",
      "\tdiesel\tfour\t186.7\t68.4\t17950.0\t\n",
      "\tgas\tfour\t186.7\t68.3\t18150.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t5572.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t7957.0\t\n",
      "\tgas\tfour\t157.3\t63.8\t6229.0\t\n",
      "\tgas\tfour\t167.3\t63.8\t6692.0\t\n",
      "\tgas\tfour\t167.3\t63.8\t7609.0\t\n",
      "\tgas\tfour\t174.6\t64.6\t8921.0\t\n",
      "\tgas\ttwo\t168.9\t68.3\t22018.0\t\n",
      "\tgas\ttwo\t186.6\t66.5\t11850.0\t\n",
      "\tgas\tfour\t186.6\t66.5\t12170.0\t\n",
      "\tgas\ttwo\t186.6\t66.5\t15040.0\t\n",
      "\tgas\tfour\t186.6\t66.5\t15510.0\t\n",
      "\tgas\ttwo\t186.6\t66.5\t18150.0\t\n",
      "\tgas\tfour\t186.6\t66.5\t18620.0\t\n",
      "\tgas\ttwo\t156.9\t63.4\t5118.0\t\n",
      "\tgas\ttwo\t157.9\t63.6\t7053.0\t\n",
      "\tgas\ttwo\t157.3\t63.8\t7603.0\t\n",
      "\tgas\tfour\t172.0\t65.4\t7126.0\t\n",
      "\tgas\tfour\t172.0\t65.4\t7775.0\t\n",
      "\tgas\tfour\t172.0\t65.4\t9960.0\t\n",
      "\tgas\tfour\t172.0\t65.4\t9233.0\t\n",
      "\tgas\tfour\t172.0\t65.4\t11259.0\t\n",
      "\tgas\tfour\t173.5\t65.4\t7463.0\t\n",
      "\tgas\tfour\t173.5\t65.4\t10198.0\t\n",
      "\tgas\tfour\t173.6\t65.4\t8013.0\t\n",
      "\tgas\tfour\t173.6\t65.4\t11694.0\t\n",
      "\tgas\ttwo\t158.7\t63.6\t5348.0\t\n",
      "\tgas\ttwo\t158.7\t63.6\t6338.0\t\n",
      "\tgas\tfour\t158.7\t63.6\t6488.0\t\n",
      "\tgas\tfour\t169.7\t63.6\t6918.0\t\n",
      "\tgas\tfour\t169.7\t63.6\t7898.0\t\n",
      "\tgas\tfour\t169.7\t63.6\t8778.0\t\n",
      "\tgas\tfour\t166.3\t64.4\t6938.0\t\n",
      "\tgas\tfour\t166.3\t64.4\t7198.0\t\n",
      "\tdiesel\tfour\t166.3\t64.4\t7898.0\t\n",
      "\tdiesel\tfour\t166.3\t64.4\t7788.0\t\n",
      "\tgas\tfour\t166.3\t64.4\t7738.0\t\n",
      "\tgas\tfour\t166.3\t64.4\t8358.0\t\n",
      "\tgas\tfour\t166.3\t64.4\t9258.0\t\n",
      "\tgas\ttwo\t168.7\t64.0\t8058.0\t\n",
      "\tgas\ttwo\t168.7\t64.0\t8238.0\t\n",
      "\tgas\ttwo\t168.7\t64.0\t9298.0\t\n",
      "\tgas\ttwo\t168.7\t64.0\t9538.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t8449.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t9639.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t9989.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t11199.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t11549.0\t\n",
      "\tgas\ttwo\t176.2\t65.6\t17669.0\t\n",
      "\tgas\tfour\t175.6\t66.5\t8948.0\t\n",
      "\tdiesel\tfour\t175.6\t66.5\t10698.0\t\n",
      "\tgas\tfour\t175.6\t66.5\t9988.0\t\n",
      "\tgas\tfour\t175.6\t66.5\t10898.0\t\n",
      "\tgas\tfour\t175.6\t66.5\t11248.0\t\n",
      "\tgas\ttwo\t183.5\t67.7\t16558.0\t\n",
      "\tgas\ttwo\t183.5\t67.7\t15998.0\t\n",
      "\tgas\tfour\t187.8\t66.5\t15690.0\t\n",
      "\tdiesel\ttwo\t171.7\t65.5\t7775.0\t\n",
      "\tgas\ttwo\t171.7\t65.5\t7975.0\t\n",
      "\tdiesel\tfour\t171.7\t65.5\t7995.0\t\n",
      "\tgas\tfour\t171.7\t65.5\t8195.0\t\n",
      "\tgas\tfour\t171.7\t65.5\t8495.0\t\n",
      "\tdiesel\tfour\t171.7\t65.5\t9495.0\t\n",
      "\tgas\tfour\t171.7\t65.5\t9995.0\t\n",
      "\tgas\ttwo\t165.7\t64.0\t9980.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t12940.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t13415.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t15985.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t16515.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t18420.0\t\n",
      "\tgas\tfour\t188.8\t67.2\t18950.0\t\n",
      "\tgas\tfour\t188.8\t68.9\t16845.0\t\n",
      "\tgas\tfour\t188.8\t68.8\t19045.0\t\n",
      "\tgas\tfour\t188.8\t68.9\t21485.0\t\n",
      "\tdiesel\tfour\t188.8\t68.9\t22470.0\t\n",
      "\tgas\tfour\t188.8\t68.9\t22625.0\t\n"
     ]
    }
   ],
   "source": [
    "!cat output_mazda/part-m-* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca46159f-00a6-41a5-a49c-3cf50530dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgas\tfour\t176.6\t66.2\t13950.0\t\n",
      "\tgas\tfour\t176.6\t66.4\t17450.0\t\n",
      "\tgas\tfour\t192.7\t71.4\t17710.0\t\n",
      "\tgas\tfour\t192.7\t71.4\t23875.0\t\n",
      "\tgas\ttwo\t176.8\t64.8\t16430.0\t\n",
      "\tgas\tfour\t176.8\t64.8\t16925.0\t\n",
      "\tgas\ttwo\t176.8\t64.8\t20970.0\t\n",
      "\tgas\tfour\t176.8\t64.8\t21105.0\t\n",
      "\tgas\ttwo\t141.1\t60.3\t5151.0\t\n",
      "\tgas\ttwo\t155.9\t63.6\t6295.0\t\n"
     ]
    }
   ],
   "source": [
    "!head output_toyota/part-m-* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45e1ee",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
